# kafka和zookeeper
## 一，
1. 组成
+ zookeeper存broker
+ 消费者
2. 台数（一般3台）
+ n= 2*（峰值生成速率*副本数/100）+ 1
3. 副本数： 2
4. 通过压测得到峰值
5. 默认存储3天
6. 数据量计算
+ 均速（条数） -->总量/(24*3600)
+ 均速m/s -->条数均速*每条日志大小
+ 均速m/s 不应超过峰值
7. 磁盘预留
+ n=log数据大小* 副本数 *3天/（0.7）  
8. 分区数设置
+ 设置分区
+ 压测达到峰值生产速率tp,tc
+ 用户期望吞吐量p-->p/min(tp,tc)
9. ISR队列（超过延时时间踢出）
10. 分区分配策略
> range(默认，数据易倾斜)
+ 数据易倾斜，分组
> robin（轮询，更平均）
+ hash随机打散，轮询减少倾斜
11. 监控器-->eagle(开源)
## 二，kafka挂掉（数据连断）
1. 短时间数据-->flume(cannel)
2. 长时间服务器日志存30天
## 三，丢数：（传输速率与可靠性成反比）
+ ack= 0-->生产者发送后不管（可靠性差）
+ ack= 1-->生产者发送后leader应答（可靠性中）
+ ack=-1-->发送后写入leader后应答（可靠性高）
生产环境一般选用ack=1
## 四，数据重复：
1. 幂等性+事务+ack=-1
2. 下一级去重（hive的dvd层），groupby 开窗
3. 幂等性（单分区，会话内不重，kafka重启易重复）
## 五，积压（生成速率 >> 消费速率）
1. 增加分区（提升并发）
2. 增加消费者消费速度
## 六，优化
1. num.network.threads-->计算型任务线程数-->cpu核数+1
2. num.id.threads-->IO密集型任务线程数-->cpu核数*2
## 七，其他
1. 高效读写--分布式分区--顺序读写--零拷贝 
2. kafka单条数据最大值1M
3. kafka数据过期删除
+ 保证无人消费
>log.cleanup.policy
+ 标记删除
+ 启用压缩
# zookeeper
1. zookeeper 安装要奇数台
2. 选举机制半数选举（pax）
3. 常用mling ——>ls,get ,create
4. zookeeper不是安装越多越好
+ 10 台服务器--->3台
+ 100台服务器--->11台
>安装zk优劣
+ 优点：可靠性高
+ 缺点：通信延时（选举）