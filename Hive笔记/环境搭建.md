# Hive环境搭建
+ 把apache-hive-3.1.2-bin.tar.gz上传到linux的/opt/software目录下
+ 解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面
```shell
tar -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/
```
+ 修改apache-hive-3.1.2-bin.tar.gz的名称为hive
```shell
mv /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive
```
+ 修改/etc/profile.d/my_env.sh，添加环境变量
```shell
sudo vim /etc/profile.d/my_env.sh
```
+ 添加内容
```shell
#HIVE_HOME
export HIVE_HOME=/opt/module/hive
export PATH=$PATH:$HIVE_HOME/bin
```
+ 重启Xshell对话框使环境变量生效或者
```shell
source /etc/profile.d/my_env.sh
```
+ 解决日志Jar包冲突，进入/opt/module/hive/lib目录
```shell
mv log4j-slf4j-impl-2.10.0.jar log4j-slf4j-impl-2.10.0.jar.bak
```
## Hive元数据配置到MySql
### 拷贝驱动
+ 将MySQL的JDBC驱动拷贝到Hive的lib目录下
```shell
cp /opt/software/mysql-connector-java-5.1.48.jar /opt/module/hive/lib/
```
### 配置Metastore到MySql
+ 在$HIVE_HOME/conf目录下新建hive-site.xml文件
```shell
vim hive-site.xml
```
+ 添加如下内容
```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://hadoop100:3306/metastore?useSSL=false</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>myself</value>
    </property>

    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
    </property>

    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://hadoop100:9083</value>
    </property>

    <property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
    </property>

    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>hadoop100</value>
    </property>

    <property>
        <name>hive.metastore.event.db.notification.api.auth</name>
        <value>false</value>
    </property>
    
    <property>
        <name>hive.cli.print.header</name>
        <value>true</value>
    </property>

    <property>
        <name>hive.cli.print.current.db</name>
        <value>true</value>
    </property>
</configuration>
```
## 启动Hive
### 初始化元数据库
+ 登陆MySQL
```shell
mysql -uroot -pmyself
```
+ 新建Hive元数据库
```sql
create database metastore;
quit;
```
+ 初始化Hive元数据库(Hive/conf下)
```shell
schematool -initSchema -dbType mysql -verbose
```
### 启动metastore和hiveserver2
+ Hive 2.x以上版本，要先启动这两个服务，否则会报错：
FAILED: HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
+ 在/opt/module/hive/bin目录编写hive服务启动脚本
```shell
vim hiveservices.sh
```
```shell
#!/bin/bash
HIVE_LOG_DIR=$HIVE_HOME/logs

mkdir -p $HIVE_LOG_DIR

#检查进程是否运行正常，参数1为进程名，参数2为进程端口
function check_process()
{
    pid=$(ps -ef 2>/dev/null | grep -v grep | grep -i $1 | awk '{print $2}')
    ppid=$(netstat -nltp 2>/dev/null | grep $2 | awk '{print $7}' | cut -d '/' -f 1)
    echo $pid
    [[ "$pid" =~ "$ppid" ]] && [ "$ppid" ] && return 0 || return 1
}

function hive_start()
{
    metapid=$(check_process HiveMetastore 9083)
    cmd="nohup hive --service metastore >$HIVE_LOG_DIR/metastore.log 2>&1 &"
    cmd=$cmd" sleep 4; hdfs dfsadmin -safemode wait >/dev/null 2>&1"
    [ -z "$metapid" ] && eval $cmd || echo "Metastroe服务已启动"
    server2pid=$(check_process HiveServer2 10000)
    cmd="nohup hive --service hiveserver2 >$HIVE_LOG_DIR/hiveServer2.log 2>&1 &"
    [ -z "$server2pid" ] && eval $cmd || echo "HiveServer2服务已启动"
}

function hive_stop()
{
    metapid=$(check_process HiveMetastore 9083)
    [ "$metapid" ] && kill $metapid || echo "Metastore服务未启动"
    server2pid=$(check_process HiveServer2 10000)
    [ "$server2pid" ] && kill $server2pid || echo "HiveServer2服务未启动"
}

case $1 in
"start")
    hive_start
    ;;
"stop")
    hive_stop
    ;;
"restart")
    hive_stop
    sleep 2
    hive_start
    ;;
"status")
    check_process HiveMetastore 9083 >/dev/null && echo "Metastore服务运行正常" || echo "Metastore服务运行异常"
    check_process HiveServer2 10000 >/dev/null && echo "HiveServer2服务运行正常" || echo "HiveServer2服务运行异常"
    ;;
*)
    echo Invalid Args!
    echo 'Usage: '$(basename $0)' start|stop|restart|status'
    ;;
esac
```
+ 添加执行权限
```shell
chmod +x hiveservices.sh
```
+ 启动Hive后台服务
```shell
hiveservices.sh start
```
+ 查看Hive后台服务运行情况
```shell
hiveservices.sh status
```
正常输出
```shell
Metastore服务运行正常
HiveServer2服务运行异常
```
+ 启动Hive客户端
```shell
bin/hive
```
### 在配置完成环境后使用

>1. 启动后台服务
```bash
hiveservices.sh start

//退出安全模式
hadoop dfsadmin -safemode leave
```
>2. 启动beeline客户端
```bash
beeline -u jdbc:hive2://hadoop100:10000 -n atguigu

hadoop fs -chmod -R 777 /tmp
```
>3.历史聚集
```bash
mapred --daemon start historyserver
```
